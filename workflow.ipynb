{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make an Antarctic Rift Catalog\n",
    "\n",
    "## Step 0: Decide which data to use\n",
    "This is done using IcePyx to spatially window available data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "shelf_name = 'amery'\n",
    "\n",
    "# Format is WSNE\n",
    "# spatial_extent = [-27.8, -76.1, -3.0, -70.2] # Brunt-Riiser-Ekstrom System\n",
    "# spatial_extent = [-3.0,-71.5, 39.5, -68.6] # Fimbul\n",
    "spatial_extent = [67.6, -72.44,74.87,-68.39] # Amery\n",
    "# spatial_extent = [159, -86, 180, -69] # East Ross\n",
    "# spatial_extent = [-180, -86, -140, -77] # West Ross\n",
    "# spatial_extent = [-65.5,-68.7,-60.2,-66] # Larsen C\n",
    "# spatial_extent = [-82.0, 82.4, -79.5, 82.9] # Milne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If filelist_file_name exists, then load it.  Otherwise query icepyx\n",
    "\n",
    "file_path = 's3://its-live-data.jpl.nasa.gov/icesat2/alt06/rel003/'\n",
    "# file_path = '/Users/lipovsky/is2-data/' + shelf_name + '/'\n",
    "\n",
    "import os.path\n",
    "import h5py\n",
    "import pickle\n",
    "\n",
    "filelist_file_name = shelf_name + '_filelist.pickle'\n",
    "if os.path.isfile(filelist_file_name):\n",
    "    with open(filelist_file_name, 'rb') as handle:\n",
    "        file_list = pickle.load(handle)\n",
    "else:       \n",
    "    import icepyx as ipx\n",
    "    date_range = ['2018-10-14','2020-12-01']\n",
    "    region_a = ipx.Query('ATL06', spatial_extent, date_range)\n",
    "    granules=region_a.granules.avail\n",
    "\n",
    "    file_list = []\n",
    "    for f in granules: \n",
    "        file_list.append(file_path + f['producer_granule_id'])\n",
    "        \n",
    "    with open(filelist_file_name, 'wb') as handle:\n",
    "        pickle.dump(file_list, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "    print('Filelist written with %d files in it.'%len(file_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Read the ATL06 files into a Python data structure\n",
    "Put the needed info in a dictionary, save the whole thing to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arc\n",
    "import numpy as np\n",
    "import importlib\n",
    "importlib.reload(arc)\n",
    "\n",
    "atl06_file_name = shelf_name + '_atl06.pickle'\n",
    "# maskfile = '/Users/lipovsky/Downloads/BedMachineAntarctica_2020-07-15_v02.nc'\n",
    "maskfile = 'BedMachineAntarctica_2020-07-15_v02.nc'\n",
    "\n",
    "if os.path.isfile(atl06_file_name):\n",
    "    print('Data already pickled, so theres no need to ingest data. \\\n",
    "To repeat the data ingest, it would probably be best to change the filename of the \\\n",
    "existing pickle file.')\n",
    "else:\n",
    "    arc.ingest(file_list,atl06_file_name,maskfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2.  Run the rift detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data (deserialize)\n",
    "with open(atl06_file_name, 'rb') as handle:\n",
    "    atl06_data = pickle.load(handle)\n",
    "\n",
    "# for i in range(len(atl06_data['quality'])):\n",
    "#     atl06_data['quality'][i] = np.array(atl06_data['quality'][i])\n",
    "#     atl06_data['h'][i] = np.array(atl06_data['h'][i])\n",
    "#     atl06_data['geoid'][i] = np.array(atl06_data['geoid'][i])\n",
    "#     atl06_data['azimuth'][i] = np.array(atl06_data['azimuth'][i])\n",
    "#     atl06_data['h_sig'][i] = np.array(atl06_data['h_sig'][i])\n",
    "\n",
    "\n",
    "# Find the rifts\n",
    "rift_obs = arc.get_rifts(atl06_data)\n",
    "\n",
    "# Store the rifts in a dataframe\n",
    "import pandas as pd\n",
    "import geopandas\n",
    "rift_obs=pd.DataFrame(rift_obs)\n",
    "rift_obs = geopandas.GeoDataFrame(rift_obs,\n",
    "                             geometry=geopandas.points_from_xy(rift_obs['x-centroid'],\n",
    "                                                               rift_obs['y-centroid']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "## Step 3. Save the rift_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rift_obs_output_file_name = shelf_name + '_rift_obs.pickle'\n",
    "with open(rift_obs_output_file_name, 'wb') as handle:\n",
    "    pickle.dump(rift_obs, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Steps.\n",
    "\n",
    "From this point, useful next steps are to quality control the data (notebook qc.ipynb) and to analyze the data (analyze_rift_measurements.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
